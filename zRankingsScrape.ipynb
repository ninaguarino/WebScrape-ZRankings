{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data From ZRankings.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "page = 0\n",
    "result = []\n",
    "\n",
    "# Loop through 7 pages of snow resort data\n",
    "while page < 8:\n",
    "    page = page + 1\n",
    "    \n",
    "    # Request to extract data from zrankings.com\n",
    "    response = requests.get('https://www.zrankings.com/ski-resorts/snow?_=1615734995765&page=' + str(page))\n",
    "    text = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Div tag where all data we want exists\n",
    "    snowTable = text.find('div', {'class': 'tableshow table-wrap'})\n",
    "    rows = snowTable.find_all('tr')\n",
    "    \n",
    "    # Iterating through each row of ski resorts and striping text from tags\n",
    "    for row in rows[1:]:\n",
    "        td = row.find_all('td')\n",
    "        snowData = {}\n",
    "        snowData['Zone'] = td[2].text.strip()\n",
    "        resortName = td[1].text.strip()\n",
    "        snowData['Resort Name'] = resortName.replace(\"\\n\",\"\")[:-2]\n",
    "        snowData['State'] = resortName.replace(\"\\n\",\"\")[-2:]\n",
    "        snowData['Base Elevation (ft)'] = re.findall('\\d+', td[6].text.strip())[0]\n",
    "        snowData['Top Elevation (ft)'] = re.findall('\\d+', td[6].text.strip())[1]\n",
    "        snowData['Snowfall Score'] = td[11].text.strip()\n",
    "        snowData['% of North-facing Terrain'] = td[12].text.strip().replace('%', '')\n",
    "        snowData['% of South-facing Terrain'] = td[15].text.strip().replace('%', '')\n",
    "        snowData['% of East-facing Terrain'] = td[13].text.strip().replace('%', '')\n",
    "        snowData['% of West-facing Terrain'] = td[14].text.strip().replace('%', '')\n",
    "        snowData['Total Snow Score With Preservation'] = td[16].text.strip()\n",
    "        \n",
    "        # Parse ski resort link to access more information on that resort\n",
    "        moreLink = td[17].a[\"href\"]\n",
    "        response = requests.get('https://www.zrankings.com' + moreLink)\n",
    "        text = BeautifulSoup(response.text, 'html.parser')\n",
    "        overallScore = text.find_all('div', {'class': 'overall-compare'})\n",
    "        \n",
    "        '''\n",
    "        Collect further information within a ski resort's provided direct link\n",
    "        Try/Exceptions are used in the case that a tag does not exist on the page.\n",
    "        '''\n",
    "        \n",
    "        for score in overallScore:\n",
    "            div1 = score.find_all('div')\n",
    "            try:\n",
    "                snowData['Overall Ranking'] =  re.sub(r\"[\\n\\t\\s]*\", \"\", div1[3].find('h4').text)  \n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                snowData['Regional Ranking'] = div1[6].find('h4').text # Rank in region\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                snowData['State Ranking'] = div1[8].find('h4').text # Rank in state\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        snowStuff = text.find_all('div', {'class': 'snow-stuff'})\n",
    "        for stuff in snowStuff:\n",
    "            div2 = stuff.find_all('div')\n",
    "            try:\n",
    "                snowData['True Snow Per Year (inches)'] = div2[1]('h3')[0].text[:-1] # True Snow Per Year\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                snowData['Snow Quality Rank'] = div2[3]('h2')[0].text # Snow quality rank\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                snowData['Dump Potential Rank'] = div2[6]('h2')[0].text # Dump Potential Rank\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                snowData['% of Days With More Than 6\" of Snow'] = div2[11]('span')[0].text.replace('%', '') #% of days with more than 6\" of snow\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                snowData['% of Months With More Than 90\" of Snow'] = div2[15]('span')[0].text.replace('%', '') # % of months with more than 90\" of snow\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                snowData['% of Months With Less Than 30\" of Snow'] = div2[19]('span')[0].text.replace('%', '') # % of months with less than 30\" of snow\n",
    "            except:\n",
    "                continue\n",
    " \n",
    "        sideStats = text.find_all('div', {'class': 'side-stats-2 clearfix'})\n",
    "        for stats in sideStats:\n",
    "            span = stats.find_all('span')\n",
    "            snowData['Acreage'] = span[0].text.replace(\"acres\", \"\").replace(',', '')\n",
    "            snowData['Total Runs'] = span[1].text\n",
    "            snowData['Longest Run (ft)'] = span[2].text.replace('ft', '').replace(',', '')\n",
    "            snowData['Lifts'] = span[3].text\n",
    "            snowData['Uphill Max (ppl/hr)'] = span[4].text.replace('ppl/hr', '').replace(',', '')\n",
    "            snowData['Terrain Parks'] = span[5].text\n",
    "            snowData['Halfpipes'] = span[7].text\n",
    "        \n",
    "        #snowData['Total Snow Score With Preservation'] = td[17].a[\"href\"]\n",
    "        result.append(snowData)\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Data to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b2d80486d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnowData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msnowData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "snowData = pd.DataFrame.from_dict(result)\n",
    "pd.set_option('display.max_columns', 35)\n",
    "snowData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowData.to_csv('zRankings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
